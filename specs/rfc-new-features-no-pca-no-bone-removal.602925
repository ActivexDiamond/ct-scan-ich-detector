=============== Features for image at index 1 ===============
len(patches_mean)=1000
len(patches_std)=1000
len(patches_var)=1000
len(corner_kitchen_rosenfeld)=128
len(daisy)=25
len(draw_multiblock_lbp)=128

patches_mean=[124.44444444444444, 0.0, 108.22222222222223, 144.22222222222223, 100.66666666666667, 0.0, 117.44444444444444, 0.0, 0.0, 115.66666666666667, 104.22222222222223, 0.0, 0.0, 103.77777777777777, 0.0, 116.22222222222223, 120.88888888888889, 0.0, 0.0, 117.0, 0.0, 51.888888888888886, 153.44444444444446, 0.0, 0.0, 119.0, 96.55555555555556, 67.77777777777777, 76.11111111111111, 108.44444444444444, 32.77777777777778, 115.0, 0.0, 85.77777777777777, 110.22222222222223, 110.11111111111111, 106.22222222222223, 33.0, 114.0, 89.44444444444444, 115.11111111111111, 0.0, 76.66666666666667, 97.88888888888889, 124.88888888888889, 105.22222222222223, 109.11111111111111, 0.0, 0.0, 106.33333333333333, 87.44444444444444, 94.33333333333333, 0.0, 120.77777777777777, 119.77777777777777, 0.0, 0.0, 87.44444444444444, 168.66666666666666, 123.66666666666667, 114.22222222222223, 122.33333333333333, 145.77777777777777, 116.44444444444444, 68.33333333333333, 0.0, 0.0, 136.11111111111111, 119.44444444444444, 0.0, 107.0, 0.0, 111.88888888888889, 0.0, 0.0, 103.77777777777777, 51.888888888888886, 90.77777777777777, 102.0, 117.77777777777777, 0.0, 98.44444444444444, 0.0, 0.0, 82.44444444444444, 0.0, 0.0, 0.0, 150.0, 67.33333333333333, 114.0, 167.11111111111111, 132.22222222222223, 28.77777777777778, 92.11111111111111, 104.11111111111111, 242.22222222222223, 20.0, 110.88888888888889, 112.11111111111111, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 81.0, 0.0, 87.44444444444444, 0.0, 140.88888888888889, 96.77777777777777, 0.0, 0.0, 0.0, 203.77777777777777, 0.0, 121.33333333333333, 0.0, 140.77777777777777, 0.0, 145.22222222222223, 142.11111111111111, 108.77777777777777, 44.111111111111114, 0.0, 78.22222222222223, 118.0, 137.66666666666666, 0.0, 77.66666666666667, 132.33333333333334, 130.11111111111111, 135.22222222222223, 99.11111111111111, 0.0, 68.11111111111111, 166.11111111111111, 83.0, 0.0, 112.55555555555556, 0.0, 114.88888888888889, 86.0, 0.0, 0.0, 134.22222222222223, 0.0, 0.0, 76.22222222222223, 0.0, 14.777777777777779, 117.88888888888889, 25.444444444444443, 79.55555555555556, 163.11111111111111, 123.66666666666667, 106.0, 0.0, 0.0, 60.22222222222222, 0.0, 0.0, 0.0, 0.0, 154.77777777777777, 0.0, 0.0, 148.66666666666666, 101.11111111111111, 239.11111111111111, 122.66666666666667, 88.0, 129.55555555555554, 77.88888888888889, 0.0, 121.88888888888889, 62.22222222222222, 95.11111111111111, 140.33333333333334, 85.77777777777777, 0.0, 138.77777777777777, 0.0, 0.0, 0.0, 0.0, 0.0, 118.88888888888889, 0.0, 126.55555555555556, 0.0, 120.0, 125.88888888888889, 129.66666666666666, 0.0, 113.88888888888889, 104.77777777777777, 0.0, 0.0, 126.44444444444444, 0.0, 0.0, 68.22222222222223, 110.66666666666667, 0.0, 128.11111111111111, 0.0, 106.55555555555556, 105.66666666666667, 0.0, 54.666666666666664, 95.33333333333333, 130.22222222222223, 110.33333333333333, 142.33333333333334, 0.0, 0.0, 141.66666666666666, 123.77777777777777, 143.22222222222223, 62.888888888888886, 111.11111111111111, 0.0, 117.44444444444444, 110.77777777777777, 113.88888888888889, 0.0, 0.0, 100.33333333333333, 144.77777777777777, 112.22222222222223, 0.0, 86.33333333333333, 138.11111111111111, 153.44444444444446, 0.0, 0.0, 100.55555555555556, 0.0, 0.0, 109.44444444444444, 231.77777777777777, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 107.0, 57.77777777777778, 74.66666666666667, 0.0, 113.88888888888889, 227.11111111111111, 116.11111111111111, 0.0, 147.55555555555554, 114.77777777777777, 55.0, 0.0, 0.0, 0.0, 78.77777777777777, 154.11111111111111, 0.0, 0.0, 78.22222222222223, 79.44444444444444, 87.0, 102.0, 0.0, 125.44444444444444, 0.0, 98.11111111111111, 113.77777777777777, 100.0, 35.666666666666664, 0.0, 132.55555555555554, 0.0, 112.11111111111111, 0.0, 128.33333333333334, 146.11111111111111, 35.55555555555556, 90.44444444444444, 110.77777777777777, 0.0, 97.44444444444444, 92.44444444444444, 121.88888888888889, 0.0, 94.44444444444444, 0.0, 0.0, 0.0, 0.0, 34.44444444444444, 0.0, 118.66666666666667, 143.11111111111111, 159.44444444444446, 119.0, 126.22222222222223, 64.88888888888889, 104.22222222222223, 0.0, 87.55555555555556, 112.88888888888889, 157.44444444444446, 121.0, 0.0, 0.0, 72.0, 0.0, 0.0, 0.0, 72.55555555555556, 106.88888888888889, 0.0, 105.22222222222223, 109.77777777777777, 80.66666666666667, 0.0, 0.0, 113.11111111111111, 0.0, 0.0, 89.0, 129.88888888888889, 0.0, 0.0, 132.66666666666666, 0.0, 132.33333333333334, 0.0, 98.44444444444444, 116.0, 0.0, 30.333333333333332, 0.0, 146.33333333333334, 132.55555555555554, 64.22222222222223, 0.0, 116.33333333333333, 0.0, 0.0, 106.0, 44.0, 120.88888888888889, 71.33333333333333, 105.77777777777777, 122.0, 0.0, 96.66666666666667, 0.0, 244.33333333333334, 151.77777777777777, 240.33333333333334, 0.0, 122.0, 62.0, 0.0, 78.55555555555556, 0.0, 242.66666666666666, 0.0, 107.44444444444444, 27.11111111111111, 210.77777777777777, 73.77777777777777, 0.0, 111.88888888888889, 111.33333333333333, 75.22222222222223, 0.0, 95.22222222222223, 0.0, 82.11111111111111, 42.22222222222222, 87.55555555555556, 38.666666666666664, 0.0, 0.0, 92.33333333333333, 155.55555555555554, 234.55555555555554, 68.88888888888889, 136.22222222222223, 76.22222222222223, 130.22222222222223, 125.33333333333333, 0.0, 0.0, 0.0, 0.0, 0.0, 147.55555555555554, 102.33333333333333, 0.0, 135.44444444444446, 130.44444444444446, 36.22222222222222, 163.88888888888889, 109.55555555555556, 0.0, 95.11111111111111, 126.77777777777777, 65.44444444444444, 100.11111111111111, 0.0, 95.66666666666667, 102.33333333333333, 0.0, 76.88888888888889, 127.11111111111111, 175.0, 51.0, 92.33333333333333, 0.0, 45.333333333333336, 0.0, 62.77777777777778, 108.77777777777777, 90.44444444444444, 108.55555555555556, 0.0, 0.0, 112.77777777777777, 0.0, 13.333333333333334, 0.0, 58.333333333333336, 42.333333333333336, 80.44444444444444, 126.33333333333333, 158.44444444444446, 98.44444444444444, 0.0, 19.333333333333332, 0.0, 58.333333333333336, 0.0, 166.88888888888889, 99.33333333333333, 0.0, 149.66666666666666, 0.0, 234.55555555555554, 170.88888888888889, 237.88888888888889, 0.0, 89.22222222222223, 98.77777777777777, 0.0, 159.11111111111111, 140.55555555555554, 75.44444444444444, 121.44444444444444, 123.11111111111111, 122.33333333333333, 55.77777777777778, 0.0, 117.33333333333333, 0.0, 57.111111111111114, 0.0, 106.0, 0.0, 59.22222222222222, 0.0, 136.33333333333334, 77.88888888888889, 137.22222222222223, 0.0, 146.88888888888889, 91.88888888888889, 145.33333333333334, 97.22222222222223, 121.44444444444444, 83.88888888888889, 0.0, 0.0, 162.11111111111111, 58.0, 0.0, 0.0, 0.0, 0.0, 105.66666666666667, 0.0, 0.0, 240.55555555555554, 95.66666666666667, 0.0, 0.0, 0.0, 0.0, 90.88888888888889, 114.55555555555556, 0.0, 144.11111111111111, 134.88888888888889, 112.33333333333333, 18.444444444444443, 0.0, 138.33333333333334, 135.33333333333334, 88.33333333333333, 53.666666666666664, 99.11111111111111, 74.88888888888889, 141.55555555555554, 0.0, 196.22222222222223, 142.88888888888889, 0.0, 106.88888888888889, 0.0, 130.77777777777777, 164.88888888888889, 83.11111111111111, 58.111111111111114, 114.0, 160.66666666666666, 231.33333333333334, 204.44444444444446, 178.33333333333334, 0.0, 125.11111111111111, 0.0, 80.88888888888889, 70.44444444444444, 79.22222222222223, 0.0, 37.0, 0.0, 47.77777777777778, 100.55555555555556, 118.66666666666667, 150.77777777777777, 143.0, 0.0, 0.0, 121.88888888888889, 0.0, 127.55555555555556, 152.0, 110.77777777777777, 0.0, 140.44444444444446, 139.0, 0.0, 139.11111111111111, 117.33333333333333, 0.0, 108.44444444444444, 0.0, 0.0, 0.0, 0.0, 120.33333333333333, 0.0, 0.0, 108.66666666666667, 239.77777777777777, 0.0, 154.55555555555554, 0.0, 109.66666666666667, 93.33333333333333, 149.11111111111111, 0.0, 125.11111111111111, 0.0, 0.0, 90.88888888888889, 96.77777777777777, 83.22222222222223, 0.0, 0.0, 95.0, 41.666666666666664, 114.22222222222223, 170.0, 77.11111111111111, 92.22222222222223, 170.44444444444446, 49.111111111111114, 0.0, 122.0, 0.0, 94.88888888888889, 207.66666666666666, 0.0, 113.77777777777777, 132.0, 32.0, 116.66666666666667, 0.0, 116.33333333333333, 42.333333333333336, 97.66666666666667, 112.0, 90.88888888888889, 0.0, 91.88888888888889, 119.44444444444444, 122.11111111111111, 118.77777777777777, 0.0, 0.0, 0.0, 113.33333333333333, 199.55555555555554, 0.0, 198.77777777777777, 133.77777777777777, 195.55555555555554, 0.0, 0.0, 121.11111111111111, 122.55555555555556, 0.0, 0.0, 80.0, 92.88888888888889, 113.66666666666667, 122.11111111111111, 144.11111111111111, 0.0, 81.11111111111111, 68.44444444444444, 74.88888888888889, 0.0, 121.33333333333333, 166.0, 127.55555555555556, 84.33333333333333, 68.22222222222223, 243.44444444444446, 108.22222222222223, 0.0, 108.11111111111111, 0.0, 0.0, 0.0, 0.0, 94.44444444444444, 0.0, 58.0, 0.0, 133.66666666666666, 104.33333333333333, 132.88888888888889, 0.0, 124.66666666666667, 0.0, 0.0, 0.0, 137.22222222222223, 138.0, 108.11111111111111, 173.22222222222223, 106.55555555555556, 0.0, 77.88888888888889, 0.0, 150.88888888888889, 0.0, 0.0, 74.22222222222223, 72.11111111111111, 167.44444444444446, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 121.88888888888889, 113.0, 144.22222222222223, 0.0, 109.0, 0.0, 0.0, 0.0, 113.88888888888889, 107.44444444444444, 0.0, 1.4444444444444444, 77.11111111111111, 102.55555555555556, 0.0, 209.22222222222223, 141.77777777777777, 77.22222222222223, 86.11111111111111, 0.0, 77.22222222222223, 98.55555555555556, 120.55555555555556, 139.88888888888889, 0.0, 35.22222222222222, 127.0, 0.0, 67.77777777777777, 0.0, 0.0, 0.0, 119.0, 0.0, 115.66666666666667, 155.55555555555554, 67.11111111111111, 123.33333333333333, 155.22222222222223, 143.77777777777777, 215.0, 0.0, 9.0, 54.77777777777778, 59.77777777777778, 116.11111111111111, 59.44444444444444, 239.55555555555554, 94.44444444444444, 83.0, 0.0, 111.0, 0.0, 71.55555555555556, 0.0, 83.22222222222223, 0.0, 104.0, 0.0, 57.666666666666664, 0.0, 0.0, 0.0, 0.0, 120.44444444444444, 0.0, 195.77777777777777, 119.33333333333333, 238.33333333333334, 0.0, 134.33333333333334, 99.33333333333333, 0.0, 63.333333333333336, 0.0, 112.88888888888889, 101.0, 234.0, 74.77777777777777, 0.0, 118.66666666666667, 0.0, 74.55555555555556, 110.55555555555556, 84.22222222222223, 114.55555555555556, 99.0, 0.0, 0.0, 86.0, 88.0, 0.0, 80.55555555555556, 136.0, 245.44444444444446, 123.0, 78.77777777777777, 0.0, 0.0, 154.55555555555554, 134.0, 55.77777777777778, 136.66666666666666, 0.0, 0.0, 0.0, 0.0, 78.66666666666667, 0.0, 82.11111111111111, 0.0, 70.0, 0.0, 237.22222222222223, 0.0, 0.0, 0.0, 106.33333333333333, 86.33333333333333, 0.0, 72.22222222222223, 89.0, 103.44444444444444, 0.0, 0.0, 0.0, 0.0, 0.0, 55.333333333333336, 0.0, 125.0, 0.0, 104.33333333333333, 0.0, 0.0, 0.0, 59.0, 72.0, 124.11111111111111, 0.0, 146.22222222222223, 86.88888888888889, 88.22222222222223, 0.0, 121.0, 220.44444444444446, 0.0, 0.0, 0.0, 0.0, 102.77777777777777, 98.55555555555556, 72.77777777777777, 0.0, 101.55555555555556, 0.0, 0.0, 0.0, 101.33333333333333, 178.33333333333334, 0.0, 0.0, 0.0, 24.0, 140.88888888888889, 110.11111111111111, 137.33333333333334, 100.44444444444444, 127.66666666666667, 50.77777777777778, 55.77777777777778, 230.22222222222223, 0.0, 0.0, 152.22222222222223, 140.22222222222223, 0.0, 0.0, 90.11111111111111, 0.0, 0.0, 0.0, 0.0, 112.88888888888889, 49.0, 0.0, 104.11111111111111, 0.0, 111.66666666666667, 116.11111111111111, 35.888888888888886, 119.77777777777777, 127.77777777777777, 37.0, 37.44444444444444, 59.22222222222222, 0.0, 0.0, 0.0, 75.88888888888889, 88.88888888888889, 0.0, 0.0, 196.22222222222223, 122.88888888888889, 0.0, 103.22222222222223, 0.0, 0.0, 91.66666666666667, 138.66666666666666, 210.77777777777777, 243.88888888888889, 109.0, 123.33333333333333, 79.77777777777777, 0.0, 0.0, 117.77777777777777, 244.88888888888889, 101.88888888888889, 103.11111111111111, 0.0, 123.22222222222223, 0.0, 0.0, 0.0, 144.88888888888889, 200.22222222222223, 130.33333333333334, 203.88888888888889, 0.0, 0.0, 128.0, 106.88888888888889, 0.0, 0.0, 45.77777777777778, 120.44444444444444, 76.88888888888889, 145.44444444444446, 119.66666666666667, 121.0, 107.44444444444444, 132.55555555555554, 0.0, 0.0, 0.0, 78.55555555555556, 0.0, 92.33333333333333, 77.33333333333333, 89.0, 85.66666666666667, 0.0, 247.44444444444446, 0.0, 106.33333333333333, 0.0, 102.55555555555556, 15.11111111111111, 49.111111111111114, 72.88888888888889, 144.55555555555554, 0.0, 89.88888888888889, 139.0, 0.0, 125.77777777777777, 72.33333333333333, 168.22222222222223, 123.88888888888889, 130.55555555555554, 165.0, 224.66666666666666, 35.888888888888886, 92.22222222222223, 94.55555555555556, 133.44444444444446, 0.0, 129.55555555555554, 0.0, 0.0, 96.66666666666667, 79.77777777777777, 0.0, 81.66666666666667, 0.0, 0.0, 0.0, 90.77777777777777, 114.22222222222223, 76.88888888888889, 0.0, 0.0, 0.0, 119.66666666666667, 47.333333333333336, 0.0, 91.77777777777777, 0.0, 111.88888888888889, 119.66666666666667, 243.88888888888889, 0.0, 0.0, 107.11111111111111, 115.33333333333333, 99.11111111111111, 0.0, 36.888888888888886, 68.33333333333333, 95.88888888888889, 0.0, 76.11111111111111, 135.66666666666666, 140.66666666666666, 101.33333333333333]
patches_std=[19.4485709906987, 0.0, 15.75350245203183, 21.70907530544044, 20.270394394014364, 0.0, 15.727619803751553, 0.0, 0.0, 19.436506316151, 25.917723570208253, 0.0, 0.0, 10.653927578104994, 0.0, 11.331154474650633, 16.161988632071544, 0.0, 0.0, 20.46134567096374, 0.0, 50.96936867580249, 11.605660602683992, 0.0, 0.0, 15.1803967156476, 17.758322688006263, 34.071094877811596, 12.23332828741444, 9.96784955200258, 17.599102109531852, 9.955456348712053, 0.0, 17.655831757856337, 16.102296439243812, 12.242407574079394, 16.34202338742243, 11.105554165971787, 17.62573875520305, 31.404568355260782, 14.502447643564206, 0.0, 10.614455552060438, 15.968332859788076, 13.025141879751418, 15.781689655897488, 6.9032109186706965, 0.0, 0.0, 16.99673171197595, 15.36309510997132, 87.90145998029081, 0.0, 15.178770099332654, 11.801862167356639, 0.0, 0.0, 11.176474410426284, 14.094916341243984, 16.97056274847714, 14.619452625243134, 21.653842358548953, 21.513705077760072, 17.613827340480174, 11.185307823708346, 0.0, 0.0, 21.870550693897055, 13.491652654809368, 0.0, 14.29063407348401, 0.0, 14.805737960102153, 0.0, 0.0, 8.953928719069236, 17.984218047094295, 12.22727168421092, 17.56258649642599, 19.158855090924973, 0.0, 31.556338018467894, 0.0, 0.0, 11.036415592745794, 0.0, 0.0, 0.0, 14.039626459101791, 21.139746660943903, 17.65093639316497, 17.110389595177704, 21.917916455000807, 13.019453630606247, 26.92972106322696, 17.85400325133737, 3.2584173996922625, 38.58612300930075, 13.502628916411833, 21.314806770278754, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 76.27581530209953, 0.0, 12.517641871562365, 0.0, 12.01336704068934, 14.374188114485536, 0.0, 0.0, 0.0, 28.55317759229757, 0.0, 86.80629777460466, 0.0, 18.413628876325863, 0.0, 12.344839477627687, 12.810104036739855, 10.4006172656325, 63.225248902360455, 0.0, 97.41181513756462, 19.235384061671343, 16.3707055437449, 0.0, 20.477630071210225, 23.6455304679576, 19.3013784449853, 19.78651492404628, 15.91256976554101, 0.0, 78.24242163436583, 13.228289924286798, 12.192894105447921, 0.0, 8.782699042386445, 0.0, 81.67883507228437, 5.436502143433364, 0.0, 0.0, 22.054366046848752, 0.0, 0.0, 13.373088879269423, 0.0, 41.79786751013815, 84.51225347637063, 5.356431463641755, 13.115818364022303, 18.101224295269486, 15.391195174153594, 9.591663046625438, 0.0, 0.0, 12.725981977197305, 0.0, 0.0, 0.0, 0.0, 13.331481352862793, 0.0, 0.0, 18.72016144279863, 16.264784347680212, 5.606433694019051, 11.440668201153676, 13.77598554651455, 16.892543464243566, 11.91119402956213, 0.0, 9.12194477856613, 17.196755364362442, 19.261039803733016, 16.726559053725836, 17.655831757856337, 0.0, 13.693289336003463, 0.0, 0.0, 0.0, 0.0, 0.0, 8.723460633951344, 0.0, 37.41987324377578, 0.0, 15.846485765339617, 16.380506330828755, 23.39040639046511, 0.0, 9.848231024960151, 25.31480804139821, 0.0, 0.0, 22.066118377433618, 0.0, 0.0, 13.717610561106218, 11.430952132988164, 0.0, 10.524515765524106, 0.0, 20.418461750262033, 38.92157356645398, 0.0, 17.29482902809713, 13.05543735171076, 15.85193838674892, 11.41149517908246, 10.98483803552272, 0.0, 0.0, 11.215069227507147, 17.472376787869585, 12.272623352430289, 49.40185431617464, 13.971752808549466, 0.0, 17.140667114666293, 37.55226810069097, 9.290908871274166, 0.0, 0.0, 12.87547194388531, 15.626030830193983, 14.273345615577604, 0.0, 14.189197769195175, 14.578861748317088, 14.111548549650239, 0.0, 0.0, 16.493171052227183, 0.0, 0.0, 11.14660995909729, 13.431122876676955, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 21.499353995462798, 11.669311869436555, 12.909944487358056, 0.0, 13.11016945771017, 7.593044250342173, 12.653014084877118, 0.0, 16.0976955639351, 21.09121869814164, 77.91448303535529, 0.0, 0.0, 0.0, 13.546445025891705, 25.518814168044916, 0.0, 0.0, 12.461298111243625, 12.508762360939997, 12.400716825158849, 13.98411797560202, 0.0, 18.11758575473694, 0.0, 14.487116456005886, 10.77835050024691, 12.901334986909086, 4.69041575982343, 0.0, 9.154368855131548, 0.0, 14.805737960102153, 0.0, 12.256517540566824, 16.189464643159106, 11.314799660534193, 17.59489263717117, 18.15842490585922, 0.0, 22.92553700382131, 11.682000505156175, 15.480772622438916, 0.0, 13.89733076778184, 0.0, 0.0, 0.0, 0.0, 5.418304595660715, 0.0, 18.55921454276674, 13.403518977777974, 63.714835375394166, 19.44793619441976, 18.8430817117334, 10.49279588251381, 62.26248697209755, 0.0, 13.630937940428108, 8.887499891476098, 12.953859237146373, 20.19350830781461, 0.0, 0.0, 11.8227652339788, 0.0, 0.0, 0.0, 85.86437770126032, 17.103894582127875, 0.0, 23.484168557551836, 11.202953755126643, 15.033296378372908, 0.0, 0.0, 19.416169918935804, 0.0, 0.0, 14.023789311975086, 13.420088130563778, 0.0, 0.0, 13.199326582148887, 0.0, 13.92838827718412, 0.0, 15.078395958833221, 23.49468024894146, 0.0, 56.8076677140605, 0.0, 8.379870059984357, 16.37824513127847, 12.638369952716545, 0.0, 13.324997394204456, 0.0, 0.0, 15.09230856356236, 67.31022705849882, 13.008069670139758, 14.173527750312866, 17.209672847156998, 14.43760521847181, 0.0, 12.875471943885309, 0.0, 3.527668414752787, 54.39317313735813, 5.887840577551898, 0.0, 10.413666234542205, 88.00505036012927, 0.0, 9.911958110295206, 0.0, 3.6817870057290865, 0.0, 12.570787221094179, 57.62029820672658, 21.0067596410604, 13.189033978421264, 0.0, 17.716561269328665, 83.89411315594333, 12.281673590062534, 0.0, 11.678829638640812, 0.0, 16.468450945465694, 80.50780193769735, 13.630937940428108, 7.4981479194679945, 0.0, 0.0, 5.811865258054232, 21.14033065604494, 11.567301722346594, 87.24479538051341, 14.195286993911258, 13.373088879269423, 20.63857110567373, 20.352450029964995, 0.0, 0.0, 0.0, 0.0, 0.0, 16.0976955639351, 26.217042802980913, 0.0, 14.392213258187073, 12.047232149715377, 6.629526173411688, 16.7162226225135, 25.621653650817876, 0.0, 33.60371819521182, 27.295818881196105, 12.52651508788113, 18.13188992076572, 0.0, 20.231987873991358, 12.265579661982732, 0.0, 8.710714276675395, 16.47519647122401, 14.36043948569201, 77.88452991448301, 11.045361017187261, 0.0, 14.757295747452437, 0.0, 17.138506208585635, 10.4006172656325, 23.533008076652727, 12.93669295806923, 0.0, 0.0, 11.291863125255556, 0.0, 24.94883653488564, 0.0, 14.39907404430345, 5.676462121975467, 6.977919319158925, 15.811388300841896, 20.056094175592786, 14.376764518649226, 0.0, 50.57887130237508, 0.0, 82.50521869015991, 0.0, 21.640725210914745, 10.944303439588001, 0.0, 11.850925889754118, 0.0, 15.685174253352262, 26.09148198356631, 3.0711722135745005, 0.0, 17.50414413013087, 15.781689655897486, 0.0, 24.560331360615024, 22.794302948622494, 15.355861067872503, 9.978990275252313, 12.160449959186401, 17.107503227141788, 18.121673811444545, 0.0, 13.333333333333334, 0.0, 21.966866182424457, 0.0, 15.542057635833022, 0.0, 84.16092756377547, 0.0, 50.9989106637474, 12.939555586086875, 18.377388145809196, 0.0, 53.652056902569385, 10.556140334678775, 10.381607668264957, 10.05294625446002, 9.978990275252313, 9.073091405597157, 0.0, 0.0, 11.159892915101974, 86.84596837057103, 0.0, 0.0, 0.0, 0.0, 26.259389854974838, 0.0, 0.0, 2.8717439962933526, 11.766241729815194, 0.0, 0.0, 0.0, 0.0, 14.639705859556091, 11.528815214362384, 0.0, 13.723009424113975, 13.560108525003645, 38.52560476127821, 52.16876696754083, 0.0, 12.622730819174327, 11.547005383792516, 11.313708498984761, 10.64581294844754, 11.474071683044965, 9.949253958010503, 15.896268682451595, 0.0, 42.78051939266484, 58.89056601385403, 0.0, 24.10368549249238, 0.0, 54.04684753429252, 11.357273190382788, 11.845716004291214, 19.980237149323578, 8.956685895029603, 47.63752022653293, 9.3571125650788, 36.7698883783732, 40.29336863003087, 0.0, 17.741629916632952, 0.0, 12.187830400712967, 15.993825969285849, 13.389695688001424, 0.0, 5.312459150169742, 0.0, 10.293231624905301, 41.69761813370988, 16.81930108205715, 57.09986919186764, 22.335820757001272, 0.0, 0.0, 16.29208699846131, 0.0, 21.182335990742175, 15.923427883328248, 14.740554623801778, 0.0, 9.499837555466247, 10.780641085864152, 0.0, 53.46326764849228, 15.762120556715853, 0.0, 11.373566929128172, 0.0, 0.0, 0.0, 0.0, 14.60593486680443, 0.0, 0.0, 16.069294390925265, 4.516089207311461, 0.0, 7.440297352348092, 0.0, 11.41149517908246, 20.412414523193153, 10.19198426263878, 0.0, 20.33302974879622, 0.0, 0.0, 21.047271897350203, 13.902659839659602, 12.434519852033583, 0.0, 0.0, 45.963753835676506, 59.43437090139379, 12.172626647777086, 13.123346456686352, 13.30367070852957, 8.120998539831824, 13.483414594819907, 10.450352938691108, 0.0, 13.968217893171309, 0.0, 12.251480132298251, 18.76166303929372, 0.0, 18.335016757728173, 11.095544651395493, 16.679994670929073, 16.034684627740923, 0.0, 15.033296378372908, 5.676462121975467, 14.406788523316205, 9.368979548370131, 21.047271897350203, 0.0, 17.729100023811725, 9.6851674810404, 16.589450760745816, 14.868144752963019, 0.0, 0.0, 0.0, 6.782329983125268, 18.080751650495994, 0.0, 47.28818921788159, 17.523176892192286, 16.241997079663648, 0.0, 0.0, 9.4215408558667, 14.016744836176093, 0.0, 0.0, 10.903618155864084, 11.608851454763533, 20.763215336529914, 22.703129713002834, 15.595187608464665, 0.0, 9.194738162478757, 20.597255001097764, 16.669629366301955, 0.0, 9.018499505645789, 12.927146286443545, 17.49356142579391, 12.01850425154663, 33.20568150107173, 3.0590888662080453, 13.34813992682774, 0.0, 16.596147106043382, 0.0, 0.0, 0.0, 0.0, 13.19184184858296, 0.0, 21.78174567027272, 0.0, 21.097656531262214, 13.341664064126334, 19.5530301399635, 0.0, 16.206994374857626, 0.0, 0.0, 0.0, 14.702817400286683, 13.2664991614216, 16.427919625134415, 30.29036435633461, 18.318849497541603, 0.0, 12.278657585370048, 0.0, 13.30367070852957, 0.0, 0.0, 12.916636798053876, 13.803738981759372, 10.122703976826998, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 14.019386929411114, 9.568466729604882, 23.30368486731362, 0.0, 21.99494891509816, 0.0, 0.0, 0.0, 9.290908871274166, 14.659931113307238, 0.0, 4.085505846855608, 12.368817822289552, 16.667407390947233, 0.0, 34.6787728149457, 21.321756117886192, 11.535238549551618, 43.2780273848172, 0.0, 15.94976682363711, 8.744663275533778, 18.0623064302499, 9.949253958010503, 0.0, 22.404254446063376, 13.038404810405298, 0.0, 21.632166264245257, 0.0, 0.0, 0.0, 19.44793619441976, 0.0, 18.565200420859092, 18.774161387462, 23.755441222051022, 14.063348739819324, 12.07180164936984, 13.926615428163105, 33.921477955222805, 0.0, 25.45584412271571, 22.899673834541726, 84.60335924218217, 33.1073823403799, 18.33703666300111, 7.544108976341313, 21.177089880398324, 25.06879423595089, 0.0, 5.185449728701348, 0.0, 13.720310258162783, 0.0, 15.178770099332656, 0.0, 13.35830993967592, 0.0, 12.147244772192398, 0.0, 0.0, 0.0, 0.0, 15.38477682726309, 0.0, 36.51416096006156, 12.346839451634757, 4.898979485566356, 0.0, 12.23837316712388, 26.816247148158354, 0.0, 14.65150731722394, 0.0, 18.585803688983486, 11.803954139750516, 12.525529485370624, 19.27449539779203, 0.0, 18.049315160907845, 0.0, 17.036634455791052, 19.253346670765872, 10.664351600623847, 10.699024993076197, 41.32257924616463, 0.0, 0.0, 11.841546445554409, 14.613540144521982, 0.0, 13.905323609731562, 21.827607391659868, 3.0590888662080453, 8.096638534327413, 11.380077892506103, 0.0, 0.0, 7.440297352348092, 24.08318915758459, 13.205872244134238, 14.313940369055928, 0.0, 0.0, 0.0, 0.0, 25.651510676761323, 0.0, 16.468450945465694, 0.0, 12.445436468396313, 0.0, 5.769224438109854, 0.0, 0.0, 0.0, 12.909944487358056, 46.960976707616865, 0.0, 10.528034297666375, 30.22875746334569, 15.91722415157109, 0.0, 0.0, 0.0, 0.0, 0.0, 78.87402050809322, 0.0, 12.780193008453876, 0.0, 14.414498873626437, 0.0, 0.0, 0.0, 18.269586141392963, 14.29063407348401, 12.896549447597252, 0.0, 8.442982329561277, 13.469673298392657, 9.86326267607651, 0.0, 13.531855420122959, 12.98812372995774, 0.0, 0.0, 0.0, 0.0, 14.581401988513218, 14.840718095168, 11.65978633097325, 0.0, 21.505095577617627, 0.0, 0.0, 0.0, 19.629909152447276, 40.29336863003087, 0.0, 0.0, 0.0, 3.1269438398822866, 17.46389573723422, 63.2480907826815, 104.8883003749968, 16.620677290057916, 18.257418583505537, 12.959576277176295, 12.053379219840549, 3.9094693523909294, 0.0, 0.0, 14.657404482814805, 15.382369256737313, 0.0, 0.0, 25.566664252257358, 0.0, 0.0, 0.0, 0.0, 14.216144534721739, 23.772065772900575, 0.0, 98.29371455483638, 0.0, 19.067132861433457, 13.502628916411833, 6.118177732416091, 51.2071561357021, 21.19107662189587, 5.497474167490214, 5.579946457550987, 25.870522812987062, 0.0, 0.0, 0.0, 9.700451815874288, 11.493422703098444, 0.0, 0.0, 42.78051939266484, 7.475061418468517, 0.0, 17.446921267902685, 0.0, 0.0, 22.410315085295483, 13.474255287605159, 21.0067596410604, 3.1426968052735442, 18.104634152000358, 15.804359454839597, 13.82250803563021, 0.0, 0.0, 11.43850978811661, 2.469567863432541, 17.348995772694963, 13.067724824879251, 0.0, 13.464172853067653, 0.0, 0.0, 0.0, 18.82341594010824, 22.019071419404575, 11.489125293076057, 29.403115649137305, 0.0, 0.0, 22.519127672072713, 7.44527358566709, 0.0, 0.0, 12.281673590062534, 15.38477682726309, 23.24480560586216, 20.624209674345295, 14.884742374510738, 12.806248474865697, 16.45270063013034, 13.992943547938813, 0.0, 0.0, 0.0, 22.36620024904201, 0.0, 17.587874611030557, 8.29993306532582, 20.47220337704545, 17.165857586111645, 0.0, 2.006163342807532, 0.0, 23.371397523944136, 0.0, 15.420845279549447, 42.7406765517202, 9.938079899999066, 33.85736238478008, 14.048417159643217, 0.0, 22.382753501769788, 22.813251509691565, 0.0, 7.020252888413918, 42.31889517566461, 9.294894390384167, 20.21794826629956, 11.786160538823216, 25.18376902336547, 13.224556283251582, 6.118177732416091, 15.59043708159145, 55.74368147773663, 15.341382750305073, 0.0, 8.029267451173185, 0.0, 0.0, 12.918548250050733, 13.82250803563021, 0.0, 115.55470085153995, 0.0, 0.0, 0.0, 16.342023387422433, 19.5492414048774, 18.728732794793284, 0.0, 0.0, 0.0, 27.768887466211375, 88.5839212899898, 0.0, 20.120623901182576, 0.0, 19.289861726619474, 24.476746334247757, 3.1426968052735442, 0.0, 0.0, 18.699045991377588, 12.543258481484521, 15.989193881733199, 0.0, 74.40645797008698, 11.185307823708346, 20.55044981635003, 0.0, 15.502289755204583, 24.48582356294261, 20.34152840318981, 49.616305563572325]
patches_var=[378.2469135802469, 0.0, 248.17283950617286, 471.28395061728384, 410.8888888888889, 0.0, 247.35802469135803, 0.0, 0.0, 377.77777777777777, 671.7283950617284, 0.0, 0.0, 113.50617283950616, 0.0, 128.39506172839506, 261.2098765432099, 0.0, 0.0, 418.6666666666667, 0.0, 2597.876543209876, 134.69135802469134, 0.0, 0.0, 230.44444444444446, 315.358024691358, 1160.8395061728395, 149.6543209876543, 99.35802469135803, 309.72839506172846, 99.11111111111111, 0.0, 311.7283950617284, 259.28395061728395, 149.87654320987653, 267.06172839506166, 123.33333333333333, 310.6666666666667, 986.246913580247, 210.320987654321, 0.0, 112.66666666666666, 254.98765432098764, 169.6543209876543, 249.06172839506175, 47.65432098765432, 0.0, 0.0, 288.8888888888889, 236.02469135802468, 7726.666666666667, 0.0, 230.39506172839504, 139.28395061728395, 0.0, 0.0, 124.91358024691357, 198.66666666666669, 288.0, 213.72839506172838, 468.8888888888889, 462.83950617283944, 310.2469135802469, 125.11111111111111, 0.0, 0.0, 478.32098765432096, 182.02469135802468, 0.0, 204.22222222222223, 0.0, 219.20987654320987, 0.0, 0.0, 80.17283950617285, 323.4320987654321, 149.50617283950615, 308.44444444444446, 367.0617283950617, 0.0, 995.8024691358023, 0.0, 0.0, 121.80246913580247, 0.0, 0.0, 0.0, 197.11111111111111, 446.8888888888889, 311.55555555555554, 292.7654320987654, 480.3950617283951, 169.50617283950618, 725.2098765432098, 318.7654320987655, 10.617283950617285, 1488.888888888889, 182.320987654321, 454.32098765432096, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5818.0, 0.0, 156.69135802469134, 0.0, 144.32098765432096, 206.61728395061724, 0.0, 0.0, 0.0, 815.283950617284, 0.0, 7535.333333333333, 0.0, 339.06172839506166, 0.0, 152.39506172839504, 164.09876543209873, 108.17283950617283, 3997.4320987654323, 0.0, 9489.061728395063, 370.0, 268.00000000000006, 0.0, 419.33333333333326, 559.1111111111111, 372.5432098765432, 391.5061728395062, 253.20987654320984, 0.0, 6121.876543209877, 174.98765432098764, 148.66666666666666, 0.0, 77.1358024691358, 0.0, 6671.432098765432, 29.555555555555557, 0.0, 0.0, 486.3950617283951, 0.0, 0.0, 178.8395061728395, 0.0, 1747.061728395062, 7142.320987654321, 28.691358024691358, 172.02469135802468, 327.65432098765433, 236.88888888888889, 92.0, 0.0, 0.0, 161.95061728395063, 0.0, 0.0, 0.0, 0.0, 177.72839506172838, 0.0, 0.0, 350.44444444444446, 264.54320987654324, 31.4320987654321, 130.88888888888889, 189.77777777777777, 285.358024691358, 141.87654320987656, 0.0, 83.20987654320987, 295.7283950617284, 370.98765432098764, 279.77777777777777, 311.7283950617284, 0.0, 187.50617283950618, 0.0, 0.0, 0.0, 0.0, 0.0, 76.09876543209877, 0.0, 1400.2469135802469, 0.0, 251.11111111111111, 268.32098765432096, 547.1111111111111, 0.0, 96.98765432098766, 640.8395061728395, 0.0, 0.0, 486.9135802469136, 0.0, 0.0, 188.17283950617283, 130.66666666666666, 0.0, 110.76543209876543, 0.0, 416.9135802469136, 1514.888888888889, 0.0, 299.1111111111111, 170.44444444444446, 251.28395061728395, 130.22222222222223, 120.66666666666667, 0.0, 0.0, 125.77777777777777, 305.2839506172839, 150.61728395061726, 2440.543209876543, 195.20987654320987, 0.0, 293.8024691358025, 1410.1728395061727, 86.32098765432099, 0.0, 0.0, 165.77777777777777, 244.17283950617286, 203.7283950617284, 0.0, 201.33333333333334, 212.5432098765432, 199.13580246913577, 0.0, 0.0, 272.0246913580247, 0.0, 0.0, 124.24691358024691, 180.39506172839504, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 462.22222222222223, 136.17283950617286, 166.66666666666666, 0.0, 171.87654320987656, 57.65432098765432, 160.09876543209873, 0.0, 259.1358024691358, 444.8395061728395, 6070.666666666667, 0.0, 0.0, 0.0, 183.50617283950612, 651.2098765432099, 0.0, 0.0, 155.28395061728395, 156.46913580246917, 153.77777777777777, 195.55555555555554, 0.0, 328.24691358024694, 0.0, 209.87654320987656, 116.17283950617282, 166.44444444444446, 22.0, 0.0, 83.80246913580248, 0.0, 219.20987654320987, 0.0, 150.22222222222223, 262.09876543209873, 128.02469135802468, 309.5802469135803, 329.7283950617284, 0.0, 525.5802469135803, 136.46913580246914, 239.6543209876543, 0.0, 193.1358024691358, 0.0, 0.0, 0.0, 0.0, 29.358024691358025, 0.0, 344.44444444444446, 179.65432098765433, 4059.5802469135797, 378.22222222222223, 355.0617283950617, 110.09876543209876, 3876.617283950617, 0.0, 185.80246913580245, 78.98765432098766, 167.80246913580243, 407.77777777777777, 0.0, 0.0, 139.77777777777777, 0.0, 0.0, 0.0, 7372.691358024691, 292.54320987654324, 0.0, 551.5061728395062, 125.50617283950616, 226.0, 0.0, 0.0, 376.98765432098764, 0.0, 0.0, 196.66666666666666, 180.0987654320988, 0.0, 0.0, 174.22222222222223, 0.0, 194.0, 0.0, 227.35802469135803, 552.0, 0.0, 3227.1111111111113, 0.0, 70.22222222222223, 268.2469135802469, 159.72839506172838, 0.0, 177.55555555555554, 0.0, 0.0, 227.77777777777777, 4530.666666666667, 169.20987654320984, 200.88888888888889, 296.17283950617286, 208.44444444444446, 0.0, 165.77777777777774, 0.0, 12.444444444444443, 2958.617283950618, 34.666666666666664, 0.0, 108.44444444444444, 7744.888888888889, 0.0, 98.24691358024693, 0.0, 13.555555555555552, 0.0, 158.02469135802468, 3320.0987654320984, 441.28395061728395, 173.95061728395063, 0.0, 313.8765432098765, 7038.222222222223, 150.83950617283952, 0.0, 136.39506172839506, 0.0, 271.2098765432099, 6481.506172839506, 185.80246913580245, 56.22222222222222, 0.0, 0.0, 33.777777777777786, 446.9135802469135, 133.80246913580245, 7611.6543209876545, 201.50617283950615, 178.8395061728395, 425.95061728395063, 414.2222222222222, 0.0, 0.0, 0.0, 0.0, 0.0, 259.1358024691358, 687.3333333333334, 0.0, 207.1358024691358, 145.1358024691358, 43.95061728395061, 279.4320987654321, 656.469135802469, 0.0, 1129.20987654321, 745.0617283950618, 156.91358024691357, 328.7654320987654, 0.0, 409.3333333333333, 150.44444444444446, 0.0, 75.87654320987654, 271.4320987654321, 206.22222222222223, 6066.0, 122.0, 0.0, 217.77777777777777, 0.0, 293.72839506172835, 108.17283950617283, 553.8024691358025, 167.35802469135803, 0.0, 0.0, 127.50617283950616, 0.0, 622.4444444444445, 0.0, 207.33333333333331, 32.22222222222222, 48.69135802469136, 250.0, 402.24691358024694, 206.69135802469134, 0.0, 2558.2222222222213, 0.0, 6807.111111111111, 0.0, 468.32098765432096, 119.77777777777777, 0.0, 140.44444444444443, 0.0, 246.02469135802468, 680.7654320987654, 9.432098765432098, 0.0, 306.3950617283951, 249.0617283950617, 0.0, 603.2098765432098, 519.5802469135801, 235.80246913580245, 99.58024691358023, 147.87654320987656, 292.6666666666667, 328.3950617283951, 0.0, 177.77777777777777, 0.0, 482.5432098765432, 0.0, 241.55555555555554, 0.0, 7083.061728395062, 0.0, 2600.8888888888887, 167.43209876543207, 337.7283950617284, 0.0, 2878.543209876543, 111.4320987654321, 107.77777777777777, 101.06172839506173, 99.58024691358024, 82.320987654321, 0.0, 0.0, 124.54320987654322, 7542.222222222223, 0.0, 0.0, 0.0, 0.0, 689.5555555555555, 0.0, 0.0, 8.246913580246915, 138.44444444444446, 0.0, 0.0, 0.0, 0.0, 214.32098765432096, 132.91358024691357, 0.0, 188.320987654321, 183.87654320987653, 1484.2222222222222, 2721.5802469135797, 0.0, 159.33333333333337, 133.33333333333334, 128.0, 113.33333333333333, 131.65432098765433, 98.98765432098766, 252.69135802469134, 0.0, 1830.1728395061727, 3468.098765432099, 0.0, 580.9876543209878, 0.0, 2921.0617283950614, 128.98765432098764, 140.320987654321, 399.20987654320993, 80.22222222222223, 2269.3333333333335, 87.55555555555556, 1352.0246913580247, 1623.5555555555557, 0.0, 314.7654320987654, 0.0, 148.54320987654322, 255.80246913580245, 179.28395061728392, 0.0, 28.22222222222222, 0.0, 105.95061728395063, 1738.6913580246912, 282.8888888888889, 3260.395061728395, 498.8888888888889, 0.0, 0.0, 265.4320987654321, 0.0, 448.6913580246913, 253.55555555555554, 217.28395061728395, 0.0, 90.24691358024693, 116.22222222222223, 0.0, 2858.320987654321, 248.44444444444446, 0.0, 129.35802469135803, 0.0, 0.0, 0.0, 0.0, 213.33333333333334, 0.0, 0.0, 258.22222222222223, 20.395061728395063, 0.0, 55.358024691358025, 0.0, 130.22222222222223, 416.6666666666667, 103.87654320987654, 0.0, 413.4320987654321, 0.0, 0.0, 442.98765432098764, 193.28395061728395, 154.6172839506173, 0.0, 0.0, 2112.6666666666665, 3532.444444444445, 148.17283950617283, 172.22222222222223, 176.98765432098764, 65.95061728395062, 181.80246913580245, 109.20987654320987, 0.0, 195.11111111111111, 0.0, 150.09876543209876, 352.00000000000006, 0.0, 336.17283950617286, 123.11111111111111, 278.22222222222223, 257.1111111111111, 0.0, 225.99999999999997, 32.22222222222222, 207.55555555555554, 87.77777777777777, 442.98765432098764, 0.0, 314.32098765432096, 93.80246913580247, 275.2098765432099, 221.06172839506175, 0.0, 0.0, 0.0, 46.0, 326.91358024691357, 0.0, 2236.1728395061727, 307.06172839506166, 263.8024691358025, 0.0, 0.0, 88.76543209876543, 196.46913580246917, 0.0, 0.0, 118.88888888888889, 134.76543209876542, 431.1111111111111, 515.4320987654321, 243.20987654320984, 0.0, 84.54320987654322, 424.2469135802469, 277.8765432098765, 0.0, 81.33333333333334, 167.11111111111111, 306.0246913580247, 144.44444444444446, 1102.617283950617, 9.358024691358025, 178.17283950617283, 0.0, 275.4320987654321, 0.0, 0.0, 0.0, 0.0, 174.02469135802468, 0.0, 474.44444444444446, 0.0, 445.1111111111111, 178.0, 382.320987654321, 0.0, 262.6666666666667, 0.0, 0.0, 0.0, 216.17283950617286, 176.0, 269.8765432098765, 917.5061728395061, 335.58024691358025, 0.0, 150.76543209876544, 0.0, 176.98765432098764, 0.0, 0.0, 166.8395061728395, 190.54320987654324, 102.46913580246913, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 196.5432098765432, 91.55555555555556, 543.0617283950618, 0.0, 483.77777777777777, 0.0, 0.0, 0.0, 86.32098765432099, 214.9135802469136, 0.0, 16.691358024691358, 152.98765432098764, 277.8024691358025, 0.0, 1202.617283950617, 454.61728395061726, 133.06172839506172, 1872.9876543209875, 0.0, 254.39506172839504, 76.46913580246914, 326.2469135802469, 98.98765432098766, 0.0, 501.95061728395063, 170.0, 0.0, 467.95061728395063, 0.0, 0.0, 0.0, 378.22222222222223, 0.0, 344.6666666666667, 352.4691358024691, 564.320987654321, 197.77777777777777, 145.72839506172838, 193.9506172839506, 1150.6666666666667, 0.0, 648.0, 524.395061728395, 7157.728395061729, 1096.0987654320988, 336.24691358024694, 56.913580246913575, 448.46913580246905, 628.4444444444445, 0.0, 26.88888888888889, 0.0, 188.2469135802469, 0.0, 230.39506172839506, 0.0, 178.44444444444446, 0.0, 147.55555555555554, 0.0, 0.0, 0.0, 0.0, 236.69135802469134, 0.0, 1333.2839506172838, 152.44444444444446, 23.999999999999996, 0.0, 149.7777777777778, 719.1111111111111, 0.0, 214.66666666666666, 0.0, 345.4320987654321, 139.33333333333334, 156.88888888888889, 371.5061728395062, 0.0, 325.77777777777777, 0.0, 290.2469135802469, 370.69135802469134, 113.7283950617284, 114.46913580246913, 1707.5555555555557, 0.0, 0.0, 140.22222222222223, 213.55555555555554, 0.0, 193.358024691358, 476.44444444444446, 9.358024691358025, 65.55555555555556, 129.50617283950615, 0.0, 0.0, 55.358024691358025, 580.0, 174.39506172839506, 204.88888888888894, 0.0, 0.0, 0.0, 0.0, 658.0000000000001, 0.0, 271.2098765432099, 0.0, 154.88888888888889, 0.0, 33.283950617283956, 0.0, 0.0, 0.0, 166.66666666666666, 2205.3333333333335, 0.0, 110.83950617283952, 913.7777777777778, 253.35802469135803, 0.0, 0.0, 0.0, 0.0, 0.0, 6221.111111111111, 0.0, 163.33333333333334, 0.0, 207.7777777777778, 0.0, 0.0, 0.0, 333.77777777777777, 204.22222222222223, 166.320987654321, 0.0, 71.28395061728396, 181.4320987654321, 97.28395061728395, 0.0, 183.11111111111111, 168.69135802469137, 0.0, 0.0, 0.0, 0.0, 212.61728395061724, 220.2469135802469, 135.95061728395063, 0.0, 462.46913580246917, 0.0, 0.0, 0.0, 385.3333333333333, 1623.5555555555557, 0.0, 0.0, 0.0, 9.777777777777779, 304.98765432098764, 4000.320987654321, 11001.555555555555, 276.24691358024694, 333.3333333333333, 167.9506172839506, 145.28395061728395, 15.283950617283953, 0.0, 0.0, 214.83950617283952, 236.61728395061724, 0.0, 0.0, 653.6543209876543, 0.0, 0.0, 0.0, 0.0, 202.09876543209876, 565.1111111111111, 0.0, 9661.654320987655, 0.0, 363.5555555555556, 182.320987654321, 37.4320987654321, 2622.172839506173, 449.06172839506166, 30.22222222222222, 31.135802469135804, 669.283950617284, 0.0, 0.0, 0.0, 94.09876543209877, 132.09876543209876, 0.0, 0.0, 1830.1728395061727, 55.87654320987655, 0.0, 304.39506172839504, 0.0, 0.0, 502.22222222222223, 181.55555555555557, 441.28395061728395, 9.87654320987654, 327.77777777777777, 249.77777777777777, 191.06172839506175, 0.0, 0.0, 130.8395061728395, 6.098765432098765, 300.98765432098764, 170.76543209876544, 0.0, 181.28395061728395, 0.0, 0.0, 0.0, 354.320987654321, 484.8395061728395, 132.0, 864.5432098765431, 0.0, 0.0, 507.1111111111111, 55.432098765432094, 0.0, 0.0, 150.83950617283952, 236.69135802469134, 540.320987654321, 425.358024691358, 221.55555555555554, 164.0, 270.69135802469134, 195.80246913580245, 0.0, 0.0, 0.0, 500.2469135802469, 0.0, 309.33333333333326, 68.88888888888887, 419.1111111111111, 294.6666666666667, 0.0, 4.0246913580246915, 0.0, 546.2222222222222, 0.0, 237.80246913580245, 1826.7654320987651, 98.76543209876543, 1146.320987654321, 197.358024691358, 0.0, 500.98765432098764, 520.4444444444445, 0.0, 49.283950617283956, 1790.888888888889, 86.39506172839506, 408.7654320987654, 138.91358024691357, 634.2222222222222, 174.88888888888889, 37.4320987654321, 243.0617283950617, 3107.3580246913575, 235.35802469135803, 0.0, 64.46913580246914, 0.0, 0.0, 166.88888888888889, 191.06172839506175, 0.0, 13352.888888888889, 0.0, 0.0, 0.0, 267.0617283950617, 382.17283950617286, 350.7654320987654, 0.0, 0.0, 0.0, 771.1111111111111, 7847.1111111111095, 0.0, 404.8395061728395, 0.0, 372.0987654320988, 599.1111111111111, 9.87654320987654, 0.0, 0.0, 349.6543209876543, 157.33333333333337, 255.65432098765436, 0.0, 5536.320987654321, 125.11111111111111, 422.320987654321, 0.0, 240.32098765432096, 599.5555555555555, 413.77777777777777, 2461.777777777778]
corner_kitchen_rosenfeld=[[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]]
daisy=[[[3.69938384e-11 2.93410566e-11 6.39821207e-11 ... 6.15640901e-03
   4.45085476e-03 1.63877875e-03]
  [1.74098264e-07 2.46423448e-07 1.37366434e-07 ... 7.05960310e-03
   5.51360013e-03 2.16338877e-03]
  [1.13108990e-05 1.66225574e-05 1.23248177e-05 ... 7.26166928e-03
   6.17727480e-03 2.60472098e-03]
  ...
  [2.02193862e-03 9.83468322e-04 2.42928711e-04 ... 9.56232654e-05
   1.86316677e-04 1.43104131e-04]
  [1.45283159e-04 7.34541593e-05 1.62354270e-05 ... 4.45778973e-05
   8.83933652e-05 6.87981317e-05]
  [1.46653005e-06 7.40504289e-07 1.54341352e-07 ... 1.73193119e-05
   3.49338951e-05 2.74974810e-05]]

 [[2.08142087e-08 2.79612888e-08 4.96550519e-08 ... 9.08759137e-03
   6.17723459e-03 2.30246496e-03]
  [7.99397876e-06 1.16837001e-05 8.34861105e-06 ... 9.18413969e-03
   6.70409355e-03 2.66469127e-03]
  [2.94947801e-04 4.53384501e-04 2.62976158e-04 ... 8.07670149e-03
   6.38982918e-03 2.73081573e-03]
  ...
  [1.19855568e-02 6.69024301e-03 1.82088964e-03 ... 1.79394198e-04
   3.41478536e-04 2.72328806e-04]
  [1.82652824e-03 9.79513028e-04 2.22481935e-04 ... 8.18094907e-05
   1.59022306e-04 1.28621591e-04]
  [4.95730983e-05 2.51262901e-05 5.30081713e-06 ... 3.61950027e-05
   7.17479312e-05 5.87658539e-05]]

 [[1.96620490e-06 2.28181310e-06 2.75386434e-06 ... 1.20620838e-02
   7.79042342e-03 2.99145892e-03]
  [9.55454688e-05 1.30601295e-04 1.21495193e-04 ... 1.05118307e-02
   7.24739638e-03 2.97319609e-03]
  [1.36983593e-03 2.03389207e-03 1.36705394e-03 ... 9.05764823e-03
   6.72042223e-03 2.96967240e-03]
  ...
  [2.05740851e-02 1.25388531e-02 4.25306609e-03 ... 3.23982015e-04
   5.99608836e-04 4.96147950e-04]
  [7.55132340e-03 4.20240504e-03 1.10080683e-03 ... 1.46307620e-04
   2.77762945e-04 2.33333563e-04]
  [5.42977802e-04 3.09997078e-04 7.67984094e-05 ... 6.57190436e-05
   1.27634439e-04 1.08694089e-04]]

 ...

 [[7.55302218e-04 2.94818528e-03 5.53549112e-03 ... 1.00199371e-02
   9.24381049e-03 6.94018378e-03]
  [3.05008743e-03 1.06294827e-02 1.86239757e-02 ... 7.81414497e-03
   7.37171527e-03 5.39305417e-03]
  [5.55063616e-03 1.36279567e-02 2.00802467e-02 ... 6.85197739e-03
   6.34130960e-03 4.45103689e-03]
  ...
  [1.25113487e-02 2.27766488e-02 1.48638341e-02 ... 4.02520440e-03
   2.92518484e-03 3.70883174e-03]
  [1.22153669e-02 2.44545647e-02 1.36088198e-02 ... 2.83279038e-03
   2.09366104e-03 3.17051632e-03]
  [4.48845490e-03 8.28659642e-03 3.98708372e-03 ... 1.82984766e-03
   1.39617227e-03 2.50291804e-03]]

 [[7.95343834e-05 3.51486662e-04 6.91828717e-04 ... 1.44926913e-02
   1.29348667e-02 9.57115097e-03]
  [7.29227147e-04 2.88220101e-03 5.30503039e-03 ... 1.01443624e-02
   9.37092790e-03 6.81381419e-03]
  [2.42595526e-03 8.16696795e-03 1.48187082e-02 ... 8.30893297e-03
   7.58881825e-03 5.36584221e-03]
  ...
  [9.40207896e-03 1.88222539e-02 1.18683844e-02 ... 3.93892722e-03
   2.93098535e-03 3.64714228e-03]
  [3.21645963e-03 6.65427129e-03 3.70276848e-03 ... 2.85587352e-03
   2.13822312e-03 3.14674060e-03]
  [4.45454846e-04 9.23332023e-04 4.66614410e-04 ... 1.98105016e-03
   1.51661358e-03 2.62853601e-03]]

 [[1.74003689e-06 7.92144757e-06 1.60535038e-05 ... 2.27438557e-02
   1.91901144e-02 1.40366447e-02]
  [3.62904169e-05 1.54665217e-04 3.09194305e-04 ... 1.58305092e-02
   1.40038357e-02 1.01797368e-02]
  [2.85884177e-04 1.19055359e-03 2.44367678e-03 ... 1.15528679e-02
   1.02716253e-02 7.37536428e-03]
  ...
  [1.68397875e-03 3.64759282e-03 2.31717171e-03 ... 3.95610511e-03
   3.03458713e-03 3.66783323e-03]
  [2.12301806e-04 4.48735419e-04 2.55253120e-04 ... 3.04616280e-03
   2.32632167e-03 3.28788191e-03]
  [9.79042434e-06 2.08019130e-05 1.07100779e-05 ... 2.02417234e-03
   1.56476919e-03 2.59043727e-03]]]
draw_multiblock_lbp=[[[0.    0.345 0.48 ]
  [0.    0.345 0.48 ]
  [0.    0.345 0.48 ]
  ...
  [0.    0.    0.   ]
  [0.    0.    0.   ]
  [0.    0.    0.   ]]

 [[0.    0.345 0.48 ]
  [0.    0.345 0.48 ]
  [0.    0.345 0.48 ]
  ...
  [0.    0.    0.   ]
  [0.    0.    0.   ]
  [0.    0.    0.   ]]

 [[0.    0.345 0.48 ]
  [0.    0.345 0.48 ]
  [0.    0.345 0.48 ]
  ...
  [0.    0.    0.   ]
  [0.    0.    0.   ]
  [0.    0.    0.   ]]

 ...

 [[0.    0.    0.   ]
  [0.    0.    0.   ]
  [0.    0.    0.   ]
  ...
  [0.    0.    0.   ]
  [0.    0.    0.   ]
  [0.    0.    0.   ]]

 [[0.    0.    0.   ]
  [0.    0.    0.   ]
  [0.    0.    0.   ]
  ...
  [0.    0.    0.   ]
  [0.    0.    0.   ]
  [0.    0.    0.   ]]

 [[0.    0.    0.   ]
  [0.    0.    0.   ]
  [0.    0.    0.   ]
  ...
  [0.    0.    0.   ]
  [0.    0.    0.   ]
  [0.    0.    0.   ]]]
==============================
patch_size=(x, 3)
Feature template={feature_template}

=====> Testing: ['patches_mean']
===> Feature subset testing at step: 1/64
Testing model.
================= About to train.
================= About to predict.
Got accuracy of <acc=72.5000%> with <n_comps=-1>.		Took <total_dur=0.1978950s> in total.<training_dur=0.1873345s>; <prediction_dur=0.0105605s>).

=====> Testing: ['patches_std']
===> Feature subset testing at step: 2/64
Testing model.
================= About to train.
================= About to predict.
Got accuracy of <acc=55.0000%> with <n_comps=-1>.		Took <total_dur=0.1979214s> in total.<training_dur=0.1873740s>; <prediction_dur=0.0105474s>).

=====> Testing: ['patches_mean', 'patches_std']
===> Feature subset testing at step: 3/64
Testing model.
================= About to train.
================= About to predict.
Got accuracy of <acc=75.0000%> with <n_comps=-1>.		Took <total_dur=0.2303324s> in total.<training_dur=0.2197193s>; <prediction_dur=0.0106132s>).

=====> Testing: ['patches_var']
===> Feature subset testing at step: 4/64
Testing model.
================= About to train.
================= About to predict.
Got accuracy of <acc=60.0000%> with <n_comps=-1>.		Took <total_dur=0.1982064s> in total.<training_dur=0.1875290s>; <prediction_dur=0.0106775s>).

=====> Testing: ['patches_mean', 'patches_var']
===> Feature subset testing at step: 5/64
Testing model.
================= About to train.
================= About to predict.
Got accuracy of <acc=77.5000%> with <n_comps=-1>.		Took <total_dur=0.2271704s> in total.<training_dur=0.2164946s>; <prediction_dur=0.0106758s>).

=====> Testing: ['patches_std', 'patches_var']
===> Feature subset testing at step: 6/64
Testing model.
================= About to train.
================= About to predict.
Got accuracy of <acc=47.5000%> with <n_comps=-1>.		Took <total_dur=0.2321562s> in total.<training_dur=0.2215998s>; <prediction_dur=0.0105564s>).

=====> Testing: ['patches_mean', 'patches_std', 'patches_var']
===> Feature subset testing at step: 7/64
Testing model.
================= About to train.
================= About to predict.
Got accuracy of <acc=62.5000%> with <n_comps=-1>.		Took <total_dur=0.2591453s> in total.<training_dur=0.2487014s>; <prediction_dur=0.0104439s>).

=====> Testing: ['corner_kitchen_rosenfeld']
===> Feature subset testing at step: 8/64
Testing model.
================= About to train.
================= About to predict.
Got accuracy of <acc=65.0000%> with <n_comps=-1>.		Took <total_dur=0.4670389s> in total.<training_dur=0.4544900s>; <prediction_dur=0.0125489s>).

=====> Testing: ['patches_mean', 'corner_kitchen_rosenfeld']
===> Feature subset testing at step: 9/64
Testing model.
================= About to train.
================= About to predict.
Got accuracy of <acc=67.5000%> with <n_comps=-1>.		Took <total_dur=0.4561011s> in total.<training_dur=0.4443427s>; <prediction_dur=0.0117584s>).

=====> Testing: ['patches_std', 'corner_kitchen_rosenfeld']
===> Feature subset testing at step: 10/64
Testing model.
================= About to train.
================= About to predict.
Got accuracy of <acc=55.0000%> with <n_comps=-1>.		Took <total_dur=0.4380122s> in total.<training_dur=0.4262856s>; <prediction_dur=0.0117266s>).

=====> Testing: ['patches_mean', 'patches_std', 'corner_kitchen_rosenfeld']
===> Feature subset testing at step: 11/64
Testing model.
================= About to train.
================= About to predict.
Got accuracy of <acc=50.0000%> with <n_comps=-1>.		Took <total_dur=0.4559725s> in total.<training_dur=0.4441503s>; <prediction_dur=0.0118223s>).

=====> Testing: ['patches_var', 'corner_kitchen_rosenfeld']
===> Feature subset testing at step: 12/64
Testing model.
================= About to train.
================= About to predict.
Got accuracy of <acc=55.0000%> with <n_comps=-1>.		Took <total_dur=0.4517353s> in total.<training_dur=0.4378886s>; <prediction_dur=0.0138467s>).

=====> Testing: ['patches_mean', 'patches_var', 'corner_kitchen_rosenfeld']
===> Feature subset testing at step: 13/64
Testing model.
================= About to train.
================= About to predict.
Got accuracy of <acc=50.0000%> with <n_comps=-1>.		Took <total_dur=0.4670835s> in total.<training_dur=0.4540467s>; <prediction_dur=0.0130369s>).

=====> Testing: ['patches_std', 'patches_var', 'corner_kitchen_rosenfeld']
===> Feature subset testing at step: 14/64
Testing model.
================= About to train.
================= About to predict.
Got accuracy of <acc=50.0000%> with <n_comps=-1>.		Took <total_dur=0.4657191s> in total.<training_dur=0.4516055s>; <prediction_dur=0.0141136s>).

=====> Testing: ['patches_mean', 'patches_std', 'patches_var', 'corner_kitchen_rosenfeld']
===> Feature subset testing at step: 15/64
Testing model.
================= About to train.
================= About to predict.
Got accuracy of <acc=52.5000%> with <n_comps=-1>.		Took <total_dur=0.4782119s> in total.<training_dur=0.4664502s>; <prediction_dur=0.0117617s>).

=====> Testing: ['daisy']
===> Feature subset testing at step: 16/64
Testing model.
================= About to train.
================= About to predict.
Got accuracy of <acc=72.5000%> with <n_comps=-1>.		Took <total_dur=1.6315228s> in total.<training_dur=1.6101163s>; <prediction_dur=0.0214065s>).

=====> Testing: ['patches_mean', 'daisy']
===> Feature subset testing at step: 17/64
Testing model.
================= About to train.
================= About to predict.
Got accuracy of <acc=72.5000%> with <n_comps=-1>.		Took <total_dur=1.4055208s> in total.<training_dur=1.3843764s>; <prediction_dur=0.0211444s>).

=====> Testing: ['patches_std', 'daisy']
===> Feature subset testing at step: 18/64
Testing model.
================= About to train.
================= About to predict.
Got accuracy of <acc=70.0000%> with <n_comps=-1>.		Took <total_dur=1.3768545s> in total.<training_dur=1.3578755s>; <prediction_dur=0.0189790s>).

=====> Testing: ['patches_mean', 'patches_std', 'daisy']
===> Feature subset testing at step: 19/64
Testing model.
================= About to train.
================= About to predict.
Got accuracy of <acc=72.5000%> with <n_comps=-1>.		Took <total_dur=1.4139908s> in total.<training_dur=1.3948170s>; <prediction_dur=0.0191737s>).

=====> Testing: ['patches_var', 'daisy']
===> Feature subset testing at step: 20/64
Testing model.
================= About to train.
================= About to predict.
Got accuracy of <acc=70.0000%> with <n_comps=-1>.		Took <total_dur=1.3945051s> in total.<training_dur=1.3751204s>; <prediction_dur=0.0193847s>).

=====> Testing: ['patches_mean', 'patches_var', 'daisy']
===> Feature subset testing at step: 21/64
Testing model.
================= About to train.
================= About to predict.
Got accuracy of <acc=72.5000%> with <n_comps=-1>.		Took <total_dur=1.4095120s> in total.<training_dur=1.3904712s>; <prediction_dur=0.0190408s>).

=====> Testing: ['patches_std', 'patches_var', 'daisy']
===> Feature subset testing at step: 22/64
Testing model.
================= About to train.
================= About to predict.
Got accuracy of <acc=70.0000%> with <n_comps=-1>.		Took <total_dur=1.4268682s> in total.<training_dur=1.4078029s>; <prediction_dur=0.0190653s>).

=====> Testing: ['patches_mean', 'patches_std', 'patches_var', 'daisy']
===> Feature subset testing at step: 23/64
Testing model.
================= About to train.
================= About to predict.
Got accuracy of <acc=72.5000%> with <n_comps=-1>.		Took <total_dur=1.4302715s> in total.<training_dur=1.4108371s>; <prediction_dur=0.0194344s>).

=====> Testing: ['corner_kitchen_rosenfeld', 'daisy']
===> Feature subset testing at step: 24/64
Testing model.
================= About to train.
================= About to predict.
Got accuracy of <acc=80.0000%> with <n_comps=-1>.		Took <total_dur=1.4522382s> in total.<training_dur=1.4320618s>; <prediction_dur=0.0201763s>).

=====> Testing: ['patches_mean', 'corner_kitchen_rosenfeld', 'daisy']
===> Feature subset testing at step: 25/64
Testing model.
================= About to train.
================= About to predict.
Got accuracy of <acc=72.5000%> with <n_comps=-1>.		Took <total_dur=1.4353885s> in total.<training_dur=1.4152546s>; <prediction_dur=0.0201339s>).

=====> Testing: ['patches_std', 'corner_kitchen_rosenfeld', 'daisy']
===> Feature subset testing at step: 26/64
Testing model.
================= About to train.
================= About to predict.
Got accuracy of <acc=72.5000%> with <n_comps=-1>.		Took <total_dur=1.4508372s> in total.<training_dur=1.4308931s>; <prediction_dur=0.0199441s>).

=====> Testing: ['patches_mean', 'patches_std', 'corner_kitchen_rosenfeld', 'daisy']
===> Feature subset testing at step: 27/64
Testing model.
================= About to train.
================= About to predict.
Got accuracy of <acc=77.5000%> with <n_comps=-1>.		Took <total_dur=1.4955108s> in total.<training_dur=1.4752429s>; <prediction_dur=0.0202678s>).

=====> Testing: ['patches_var', 'corner_kitchen_rosenfeld', 'daisy']
===> Feature subset testing at step: 28/64
Testing model.
================= About to train.
================= About to predict.
Got accuracy of <acc=72.5000%> with <n_comps=-1>.		Took <total_dur=1.4365902s> in total.<training_dur=1.4144790s>; <prediction_dur=0.0221112s>).

=====> Testing: ['patches_mean', 'patches_var', 'corner_kitchen_rosenfeld', 'daisy']
===> Feature subset testing at step: 29/64
Testing model.
================= About to train.
================= About to predict.
Got accuracy of <acc=77.5000%> with <n_comps=-1>.		Took <total_dur=1.4622733s> in total.<training_dur=1.4421982s>; <prediction_dur=0.0200751s>).

=====> Testing: ['patches_std', 'patches_var', 'corner_kitchen_rosenfeld', 'daisy']
===> Feature subset testing at step: 30/64
Testing model.
================= About to train.
================= About to predict.
Got accuracy of <acc=75.0000%> with <n_comps=-1>.		Took <total_dur=1.4443612s> in total.<training_dur=1.4240945s>; <prediction_dur=0.0202667s>).

=====> Testing: ['patches_mean', 'patches_std', 'patches_var', 'corner_kitchen_rosenfeld', 'daisy']
===> Feature subset testing at step: 31/64
Testing model.
================= About to train.
================= About to predict.
Got accuracy of <acc=75.0000%> with <n_comps=-1>.		Took <total_dur=1.4933368s> in total.<training_dur=1.4716621s>; <prediction_dur=0.0216747s>).

=====> Testing: ['draw_multiblock_lbp']
===> Feature subset testing at step: 32/64
Testing model.
================= About to train.
================= About to predict.
Got accuracy of <acc=75.0000%> with <n_comps=-1>.		Took <total_dur=0.7131014s> in total.<training_dur=0.6987343s>; <prediction_dur=0.0143672s>).

=====> Testing: ['patches_mean', 'draw_multiblock_lbp']
===> Feature subset testing at step: 33/64
Testing model.
================= About to train.
================= About to predict.
Got accuracy of <acc=77.5000%> with <n_comps=-1>.		Took <total_dur=0.6698340s> in total.<training_dur=0.6557790s>; <prediction_dur=0.0140549s>).

=====> Testing: ['patches_std', 'draw_multiblock_lbp']
===> Feature subset testing at step: 34/64
Testing model.
================= About to train.
================= About to predict.
Got accuracy of <acc=77.5000%> with <n_comps=-1>.		Took <total_dur=0.6780977s> in total.<training_dur=0.6623066s>; <prediction_dur=0.0157910s>).

=====> Testing: ['patches_mean', 'patches_std', 'draw_multiblock_lbp']
===> Feature subset testing at step: 35/64
Testing model.
================= About to train.
================= About to predict.
Got accuracy of <acc=77.5000%> with <n_comps=-1>.		Took <total_dur=0.7246218s> in total.<training_dur=0.7083585s>; <prediction_dur=0.0162633s>).

=====> Testing: ['patches_var', 'draw_multiblock_lbp']
===> Feature subset testing at step: 36/64
Testing model.
================= About to train.
================= About to predict.
Got accuracy of <acc=77.5000%> with <n_comps=-1>.		Took <total_dur=0.6694554s> in total.<training_dur=0.6550412s>; <prediction_dur=0.0144142s>).

=====> Testing: ['patches_mean', 'patches_var', 'draw_multiblock_lbp']
===> Feature subset testing at step: 37/64
Testing model.
================= About to train.
================= About to predict.
Got accuracy of <acc=77.5000%> with <n_comps=-1>.		Took <total_dur=0.6659755s> in total.<training_dur=0.6518777s>; <prediction_dur=0.0140978s>).

=====> Testing: ['patches_std', 'patches_var', 'draw_multiblock_lbp']
===> Feature subset testing at step: 38/64
Testing model.
================= About to train.
================= About to predict.
Got accuracy of <acc=72.5000%> with <n_comps=-1>.		Took <total_dur=0.6674879s> in total.<training_dur=0.6524038s>; <prediction_dur=0.0150841s>).

=====> Testing: ['patches_mean', 'patches_std', 'patches_var', 'draw_multiblock_lbp']
===> Feature subset testing at step: 39/64
Testing model.
================= About to train.
================= About to predict.
Got accuracy of <acc=72.5000%> with <n_comps=-1>.		Took <total_dur=0.7409824s> in total.<training_dur=0.7267698s>; <prediction_dur=0.0142126s>).

=====> Testing: ['corner_kitchen_rosenfeld', 'draw_multiblock_lbp']
===> Feature subset testing at step: 40/64
Testing model.
================= About to train.
================= About to predict.
Got accuracy of <acc=75.0000%> with <n_comps=-1>.		Took <total_dur=0.7928305s> in total.<training_dur=0.7695814s>; <prediction_dur=0.0232491s>).

=====> Testing: ['patches_mean', 'corner_kitchen_rosenfeld', 'draw_multiblock_lbp']
===> Feature subset testing at step: 41/64
Testing model.
================= About to train.
================= About to predict.
Got accuracy of <acc=67.5000%> with <n_comps=-1>.		Took <total_dur=0.8453633s> in total.<training_dur=0.8297517s>; <prediction_dur=0.0156116s>).

=====> Testing: ['patches_std', 'corner_kitchen_rosenfeld', 'draw_multiblock_lbp']
===> Feature subset testing at step: 42/64
Testing model.
================= About to train.
================= About to predict.
Got accuracy of <acc=67.5000%> with <n_comps=-1>.		Took <total_dur=0.8083212s> in total.<training_dur=0.7899492s>; <prediction_dur=0.0183720s>).

=====> Testing: ['patches_mean', 'patches_std', 'corner_kitchen_rosenfeld', 'draw_multiblock_lbp']
===> Feature subset testing at step: 43/64
Testing model.
================= About to train.
================= About to predict.
Got accuracy of <acc=72.5000%> with <n_comps=-1>.		Took <total_dur=0.8329983s> in total.<training_dur=0.8174859s>; <prediction_dur=0.0155124s>).

=====> Testing: ['patches_var', 'corner_kitchen_rosenfeld', 'draw_multiblock_lbp']
===> Feature subset testing at step: 44/64
Testing model.
================= About to train.
================= About to predict.
Got accuracy of <acc=67.5000%> with <n_comps=-1>.		Took <total_dur=0.7733248s> in total.<training_dur=0.7581581s>; <prediction_dur=0.0151667s>).

=====> Testing: ['patches_mean', 'patches_var', 'corner_kitchen_rosenfeld', 'draw_multiblock_lbp']
===> Feature subset testing at step: 45/64
Testing model.
================= About to train.
================= About to predict.
Got accuracy of <acc=72.5000%> with <n_comps=-1>.		Took <total_dur=0.8419502s> in total.<training_dur=0.8264436s>; <prediction_dur=0.0155066s>).

=====> Testing: ['patches_std', 'patches_var', 'corner_kitchen_rosenfeld', 'draw_multiblock_lbp']
===> Feature subset testing at step: 46/64
Testing model.
================= About to train.
================= About to predict.
Got accuracy of <acc=75.0000%> with <n_comps=-1>.		Took <total_dur=0.7899748s> in total.<training_dur=0.7746675s>; <prediction_dur=0.0153072s>).

=====> Testing: ['patches_mean', 'patches_std', 'patches_var', 'corner_kitchen_rosenfeld', 'draw_multiblock_lbp']
===> Feature subset testing at step: 47/64
Testing model.
================= About to train.
================= About to predict.
Got accuracy of <acc=77.5000%> with <n_comps=-1>.		Took <total_dur=0.8010643s> in total.<training_dur=0.7855622s>; <prediction_dur=0.0155021s>).

=====> Testing: ['daisy', 'draw_multiblock_lbp']
===> Feature subset testing at step: 48/64
Testing model.
================= About to train.
================= About to predict.
Got accuracy of <acc=75.0000%> with <n_comps=-1>.		Took <total_dur=1.7907435s> in total.<training_dur=1.7671367s>; <prediction_dur=0.0236068s>).

=====> Testing: ['patches_mean', 'daisy', 'draw_multiblock_lbp']
===> Feature subset testing at step: 49/64
Testing model.
================= About to train.
================= About to predict.
Got accuracy of <acc=80.0000%> with <n_comps=-1>.		Took <total_dur=1.5301690s> in total.<training_dur=1.5078073s>; <prediction_dur=0.0223617s>).

=====> Testing: ['patches_std', 'daisy', 'draw_multiblock_lbp']
===> Feature subset testing at step: 50/64
Testing model.
================= About to train.
================= About to predict.
Got accuracy of <acc=77.5000%> with <n_comps=-1>.		Took <total_dur=1.6348484s> in total.<training_dur=1.6114258s>; <prediction_dur=0.0234226s>).

=====> Testing: ['patches_mean', 'patches_std', 'daisy', 'draw_multiblock_lbp']
===> Feature subset testing at step: 51/64
Testing model.
================= About to train.
================= About to predict.
Got accuracy of <acc=80.0000%> with <n_comps=-1>.		Took <total_dur=1.5218329s> in total.<training_dur=1.4995176s>; <prediction_dur=0.0223153s>).

=====> Testing: ['patches_var', 'daisy', 'draw_multiblock_lbp']
===> Feature subset testing at step: 52/64
Testing model.
================= About to train.
================= About to predict.
Got accuracy of <acc=77.5000%> with <n_comps=-1>.		Took <total_dur=1.6627402s> in total.<training_dur=1.6406435s>; <prediction_dur=0.0220967s>).

=====> Testing: ['patches_mean', 'patches_var', 'daisy', 'draw_multiblock_lbp']
===> Feature subset testing at step: 53/64
Testing model.
================= About to train.
================= About to predict.
Got accuracy of <acc=80.0000%> with <n_comps=-1>.		Took <total_dur=1.5508014s> in total.<training_dur=1.5284011s>; <prediction_dur=0.0224003s>).

=====> Testing: ['patches_std', 'patches_var', 'daisy', 'draw_multiblock_lbp']
===> Feature subset testing at step: 54/64
Testing model.
================= About to train.
================= About to predict.
Got accuracy of <acc=80.0000%> with <n_comps=-1>.		Took <total_dur=1.4969160s> in total.<training_dur=1.4749579s>; <prediction_dur=0.0219581s>).

=====> Testing: ['patches_mean', 'patches_std', 'patches_var', 'daisy', 'draw_multiblock_lbp']
===> Feature subset testing at step: 55/64
Testing model.
================= About to train.
================= About to predict.
Got accuracy of <acc=77.5000%> with <n_comps=-1>.		Took <total_dur=1.5351419s> in total.<training_dur=1.5129912s>; <prediction_dur=0.0221507s>).

=====> Testing: ['corner_kitchen_rosenfeld', 'daisy', 'draw_multiblock_lbp']
===> Feature subset testing at step: 56/64
Testing model.
================= About to train.
================= About to predict.
Got accuracy of <acc=75.0000%> with <n_comps=-1>.		Took <total_dur=1.5603930s> in total.<training_dur=1.5373634s>; <prediction_dur=0.0230296s>).

=====> Testing: ['patches_mean', 'corner_kitchen_rosenfeld', 'daisy', 'draw_multiblock_lbp']
===> Feature subset testing at step: 57/64
Testing model.
================= About to train.
================= About to predict.
Got accuracy of <acc=77.5000%> with <n_comps=-1>.		Took <total_dur=1.5550405s> in total.<training_dur=1.5315177s>; <prediction_dur=0.0235228s>).

=====> Testing: ['patches_std', 'corner_kitchen_rosenfeld', 'daisy', 'draw_multiblock_lbp']
===> Feature subset testing at step: 58/64
Testing model.
================= About to train.
================= About to predict.
Got accuracy of <acc=72.5000%> with <n_comps=-1>.		Took <total_dur=1.5500231s> in total.<training_dur=1.5255562s>; <prediction_dur=0.0244669s>).

=====> Testing: ['patches_mean', 'patches_std', 'corner_kitchen_rosenfeld', 'daisy', 'draw_multiblock_lbp']
===> Feature subset testing at step: 59/64
Testing model.
================= About to train.
================= About to predict.
Got accuracy of <acc=82.5000%> with <n_comps=-1>.		Took <total_dur=1.6107458s> in total.<training_dur=1.5858789s>; <prediction_dur=0.0248669s>).

=====> Testing: ['patches_var', 'corner_kitchen_rosenfeld', 'daisy', 'draw_multiblock_lbp']
===> Feature subset testing at step: 60/64
Testing model.
================= About to train.
================= About to predict.
Got accuracy of <acc=72.5000%> with <n_comps=-1>.		Took <total_dur=1.5722991s> in total.<training_dur=1.5488585s>; <prediction_dur=0.0234405s>).

=====> Testing: ['patches_mean', 'patches_var', 'corner_kitchen_rosenfeld', 'daisy', 'draw_multiblock_lbp']
===> Feature subset testing at step: 61/64
Testing model.
================= About to train.
================= About to predict.
Got accuracy of <acc=82.5000%> with <n_comps=-1>.		Took <total_dur=1.6070401s> in total.<training_dur=1.5836990s>; <prediction_dur=0.0233412s>).

=====> Testing: ['patches_std', 'patches_var', 'corner_kitchen_rosenfeld', 'daisy', 'draw_multiblock_lbp']
===> Feature subset testing at step: 62/64
Testing model.
================= About to train.
================= About to predict.
Got accuracy of <acc=82.5000%> with <n_comps=-1>.		Took <total_dur=1.5693848s> in total.<training_dur=1.5456508s>; <prediction_dur=0.0237341s>).

=====> Testing: ['patches_mean', 'patches_std', 'patches_var', 'corner_kitchen_rosenfeld', 'daisy', 'draw_multiblock_lbp']
===> Feature subset testing at step: 63/64
Testing model.
================= About to train.
================= About to predict.
Got accuracy of <acc=72.5000%> with <n_comps=-1>.		Took <total_dur=1.6178066s> in total.<training_dur=1.5937497s>; <prediction_dur=0.0240569s>).
Tests done. <best=82.5000%>
